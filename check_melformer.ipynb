{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看模型的内容，参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import demix, get_model_from_config\n",
    "import json\n",
    "\n",
    "model_type = 'mel_band_roformer'\n",
    "config_path = 'configs/KimberleyJensen/config_musdb18_vocals_mel_band_roformer_kj_with_augue.yaml'\n",
    "model, config = get_model_from_config(model_type, config_path)\n",
    "\n",
    "# 计算模型的总参数量\n",
    "total_params = sum(param.numel() for param in model.state_dict().values())\n",
    "\n",
    "# 打印总参数量，单位是个数\n",
    "print(f\"Total number of parameters: {total_params}, {total_params/1e6:.2f}M\")\n",
    "\n",
    "# 如果需要显示以MB为单位的参数量\n",
    "params_in_mb = total_params * 4 / 1e6  # 假设每个参数占 4 字节（float32）\n",
    "print(f\"Total number of parameters (in MB): {params_in_mb:.2f} MB\")\n",
    "print(json.dumps(list(model.state_dict().keys())[:40], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"name\": \"layers.0.0.layers.0.0.rotary_embed.freqs\",\n",
      "        \"shape\": [\n",
      "            32\n",
      "        ],\n",
      "        \"num_params\": 32\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.0.layers.0.0.norm.gamma\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.0.layers.0.0.to_qkv.weight\",\n",
      "        \"shape\": [\n",
      "            1536,\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 589824\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.0.layers.0.0.to_gates.weight\",\n",
      "        \"shape\": [\n",
      "            8,\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 3072\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.0.layers.0.0.to_gates.bias\",\n",
      "        \"shape\": [\n",
      "            8\n",
      "        ],\n",
      "        \"num_params\": 8\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.0.layers.0.0.to_out.0.weight\",\n",
      "        \"shape\": [\n",
      "            384,\n",
      "            512\n",
      "        ],\n",
      "        \"num_params\": 196608\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.0.layers.0.1.net.0.gamma\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.0.layers.0.1.net.1.weight\",\n",
      "        \"shape\": [\n",
      "            1536,\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 589824\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.0.layers.0.1.net.1.bias\",\n",
      "        \"shape\": [\n",
      "            1536\n",
      "        ],\n",
      "        \"num_params\": 1536\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.0.layers.0.1.net.4.weight\",\n",
      "        \"shape\": [\n",
      "            384,\n",
      "            1536\n",
      "        ],\n",
      "        \"num_params\": 589824\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.0.layers.0.1.net.4.bias\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.0.norm.gamma\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.1.layers.0.0.rotary_embed.freqs\",\n",
      "        \"shape\": [\n",
      "            32\n",
      "        ],\n",
      "        \"num_params\": 32\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.1.layers.0.0.norm.gamma\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.1.layers.0.0.to_qkv.weight\",\n",
      "        \"shape\": [\n",
      "            1536,\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 589824\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.1.layers.0.0.to_gates.weight\",\n",
      "        \"shape\": [\n",
      "            8,\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 3072\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.1.layers.0.0.to_gates.bias\",\n",
      "        \"shape\": [\n",
      "            8\n",
      "        ],\n",
      "        \"num_params\": 8\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.1.layers.0.0.to_out.0.weight\",\n",
      "        \"shape\": [\n",
      "            384,\n",
      "            512\n",
      "        ],\n",
      "        \"num_params\": 196608\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.1.layers.0.1.net.0.gamma\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.1.layers.0.1.net.1.weight\",\n",
      "        \"shape\": [\n",
      "            1536,\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 589824\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.1.layers.0.1.net.1.bias\",\n",
      "        \"shape\": [\n",
      "            1536\n",
      "        ],\n",
      "        \"num_params\": 1536\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.1.layers.0.1.net.4.weight\",\n",
      "        \"shape\": [\n",
      "            384,\n",
      "            1536\n",
      "        ],\n",
      "        \"num_params\": 589824\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.1.layers.0.1.net.4.bias\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.0.1.norm.gamma\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.0.layers.0.0.rotary_embed.freqs\",\n",
      "        \"shape\": [\n",
      "            32\n",
      "        ],\n",
      "        \"num_params\": 32\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.0.layers.0.0.norm.gamma\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.0.layers.0.0.to_qkv.weight\",\n",
      "        \"shape\": [\n",
      "            1536,\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 589824\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.0.layers.0.0.to_gates.weight\",\n",
      "        \"shape\": [\n",
      "            8,\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 3072\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.0.layers.0.0.to_gates.bias\",\n",
      "        \"shape\": [\n",
      "            8\n",
      "        ],\n",
      "        \"num_params\": 8\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.0.layers.0.0.to_out.0.weight\",\n",
      "        \"shape\": [\n",
      "            384,\n",
      "            512\n",
      "        ],\n",
      "        \"num_params\": 196608\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.0.layers.0.1.net.0.gamma\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.0.layers.0.1.net.1.weight\",\n",
      "        \"shape\": [\n",
      "            1536,\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 589824\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.0.layers.0.1.net.1.bias\",\n",
      "        \"shape\": [\n",
      "            1536\n",
      "        ],\n",
      "        \"num_params\": 1536\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.0.layers.0.1.net.4.weight\",\n",
      "        \"shape\": [\n",
      "            384,\n",
      "            1536\n",
      "        ],\n",
      "        \"num_params\": 589824\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.0.layers.0.1.net.4.bias\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.0.norm.gamma\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.1.layers.0.0.rotary_embed.freqs\",\n",
      "        \"shape\": [\n",
      "            32\n",
      "        ],\n",
      "        \"num_params\": 32\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.1.layers.0.0.norm.gamma\",\n",
      "        \"shape\": [\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 384\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.1.layers.0.0.to_qkv.weight\",\n",
      "        \"shape\": [\n",
      "            1536,\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 589824\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"layers.1.1.layers.0.0.to_gates.weight\",\n",
      "        \"shape\": [\n",
      "            8,\n",
      "            384\n",
      "        ],\n",
      "        \"num_params\": 3072\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# 获取模型的参数字典\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# 计算并显示每个参数的大小和参数量\n",
    "parameter_info = []\n",
    "for name, param in state_dict.items():\n",
    "    num_params = param.numel()  # 获取参数的数量（numel 返回参数的元素数量）\n",
    "    parameter_info.append({\n",
    "        'name': name,\n",
    "        'shape': list(param.shape),\n",
    "        'num_params': num_params\n",
    "    })\n",
    "\n",
    "# 打印前40个参数的名称、形状和数量\n",
    "print(json.dumps(parameter_info[:40], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"layer\": \"layers.0.0\",\n",
      "        \"num_params (MB)\": 1.972264\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"layers.0.1\",\n",
      "        \"num_params (MB)\": 1.972264\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"layers.1.0\",\n",
      "        \"num_params (MB)\": 1.972264\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"layers.1.1\",\n",
      "        \"num_params (MB)\": 1.972264\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"layers.2.0\",\n",
      "        \"num_params (MB)\": 1.972264\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"layers.2.1\",\n",
      "        \"num_params (MB)\": 1.972264\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"layers.3.0\",\n",
      "        \"num_params (MB)\": 1.972264\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"layers.3.1\",\n",
      "        \"num_params (MB)\": 1.972264\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"layers.4.0\",\n",
      "        \"num_params (MB)\": 1.972264\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"layers.4.1\",\n",
      "        \"num_params (MB)\": 1.972264\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"layers.5.0\",\n",
      "        \"num_params (MB)\": 1.972264\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"layers.5.1\",\n",
      "        \"num_params (MB)\": 1.972264\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.0\",\n",
      "        \"num_params (MB)\": 0.011164\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.1\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.2\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.3\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.4\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.5\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.6\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.7\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.8\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.9\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.10\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.11\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.12\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.13\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.14\",\n",
      "        \"num_params (MB)\": 0.009624\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.15\",\n",
      "        \"num_params (MB)\": 0.011164\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.16\",\n",
      "        \"num_params (MB)\": 0.011164\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.17\",\n",
      "        \"num_params (MB)\": 0.011164\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.18\",\n",
      "        \"num_params (MB)\": 0.014244\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.19\",\n",
      "        \"num_params (MB)\": 0.014244\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.20\",\n",
      "        \"num_params (MB)\": 0.014244\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.21\",\n",
      "        \"num_params (MB)\": 0.015784\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.22\",\n",
      "        \"num_params (MB)\": 0.015784\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.23\",\n",
      "        \"num_params (MB)\": 0.017324\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.24\",\n",
      "        \"num_params (MB)\": 0.020404\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.25\",\n",
      "        \"num_params (MB)\": 0.020404\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.26\",\n",
      "        \"num_params (MB)\": 0.020404\n",
      "    },\n",
      "    {\n",
      "        \"layer\": \"band_split.to_features.27\",\n",
      "        \"num_params (MB)\": 0.023484\n",
      "    }\n",
      "]\n",
      "Total number of parameters(MB): 228.20\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# 获取模型的参数字典\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# 用 defaultdict 按层（前缀）分组\n",
    "layer_params = defaultdict(int)  # 默认每组的参数量为 0\n",
    "\n",
    "# 将每个参数按其层（前缀）进行分组，并计算每组的参数量\n",
    "for name, param in state_dict.items():\n",
    "    # 获取层的前缀部分（例如 layers.0.0, layers.0.1 等）\n",
    "    prefix_parts = name.split('.')[:3]  # 提取前三部分作为层的前缀\n",
    "    layer_prefix = '.'.join(prefix_parts)  # 拼接成前缀，如 layers.0.0\n",
    "    num_params = param.numel()  # 获取该参数的元素数量\n",
    "    \n",
    "    # 累加每一层的参数量\n",
    "    layer_params[layer_prefix] += num_params\n",
    "\n",
    "# 将每个层的参数信息整理成字典形式\n",
    "# layer_info = [{'layer': layer, 'num_params': num_params} for layer, num_params in layer_params.items()]\n",
    "layer_info = [{'layer': layer, 'num_params (MB)': num_params / 1e6} for layer, num_params in layer_params.items()]\n",
    "\n",
    "# 打印前40个层的名称和参数量\n",
    "print(json.dumps(layer_info[:40], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: 10000.0\n"
     ]
    }
   ],
   "source": [
    "from rotary_embedding_torch import RotaryEmbedding\n",
    "rope = RotaryEmbedding(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看Melformer mel band得到的内容是什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 28, 28, 28, 36, 36, 36, 40, 40, 44, 52, 52, 52, 60, 64, 68, 76, 80, 80, 88, 96, 104, 112, 116, 124, 132, 144, 156, 164, 176, 188, 200, 216, 228, 244, 264, 284, 304, 320, 344, 372, 396, 420, 452, 488, 520)\n"
     ]
    }
   ],
   "source": [
    "print(model.freq_per_bands_with_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freqs_per_band: torch.Size([60, 1025]), tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ...,  True,  True,  True]])\n",
      "repeated_freq_indices: torch.Size([60, 1025]), tensor([[   0,    1,    2,  ..., 1022, 1023, 1024],\n",
      "        [   0,    1,    2,  ..., 1022, 1023, 1024],\n",
      "        [   0,    1,    2,  ..., 1022, 1023, 1024],\n",
      "        ...,\n",
      "        [   0,    1,    2,  ..., 1022, 1023, 1024],\n",
      "        [   0,    1,    2,  ..., 1022, 1023, 1024],\n",
      "        [   0,    1,    2,  ..., 1022, 1023, 1024]])\n",
      "1:freq_indices: torch.Size([1979]), tensor([   0,    1,    2,  ..., 1022, 1023, 1024])\n",
      "2:freq_indices: torch.Size([1979, 2]), tensor([[   0,    0],\n",
      "        [   1,    1],\n",
      "        [   2,    2],\n",
      "        ...,\n",
      "        [1022, 1022],\n",
      "        [1023, 1023],\n",
      "        [1024, 1024]])\n",
      "3:freq_indices: torch.Size([1979, 2]), tensor([[   0,    1],\n",
      "        [   2,    3],\n",
      "        [   4,    5],\n",
      "        ...,\n",
      "        [2044, 2045],\n",
      "        [2046, 2047],\n",
      "        [2048, 2049]])\n",
      "4:freq_indices: torch.Size([3958]), tensor([   0,    1,    2,  ..., 2047, 2048, 2049])\n",
      "num_freqs_per_band: torch.Size([60]), tensor([  7,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,   7,   7,   7,   9,   9,   9,  10,  10,  11,  13,  13,  13,  15,\n",
      "         16,  17,  19,  20,  20,  22,  24,  26,  28,  29,  31,  33,  36,  39,\n",
      "         41,  44,  47,  50,  54,  57,  61,  66,  71,  76,  80,  86,  93,  99,\n",
      "        105, 113, 122, 130])\n",
      "num_bands_per_freq: torch.Size([1025]), tensor([1, 1, 1,  ..., 1, 1, 1])\n",
      "freqs: 1025 \n",
      "mel_filter_bank_numpy: (60, 1025) ,content: [[1.0000000e+00 5.0090719e-03 1.0018144e-02 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 2.1421709e-05\n",
      "  1.0710854e-05 1.0000000e+00]] \n",
      "freqs_per_band: torch.Size([60, 1025]) ,content: tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ...,  True,  True,  True]]) \n",
      "freq_indices: torch.Size([3958]) ,content: tensor([   0,    1,    2,  ..., 2047, 2048, 2049]) \n",
      "num_freqs_per_band: torch.Size([60]) ,content: tensor([  7,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "          6,   7,   7,   7,   9,   9,   9,  10,  10,  11,  13,  13,  13,  15,\n",
      "         16,  17,  19,  20,  20,  22,  24,  26,  28,  29,  31,  33,  36,  39,\n",
      "         41,  44,  47,  50,  54,  57,  61,  66,  71,  76,  80,  86,  93,  99,\n",
      "        105, 113, 122, 130]) \n",
      "freqs_per_bands_with_complex: (28, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 28, 28, 28, 36, 36, 36, 40, 40, 44, 52, 52, 52, 60, 64, 68, 76, 80, 80, 88, 96, 104, 112, 116, 124, 132, 144, 156, 164, 176, 188, 200, 216, 228, 244, 264, 284, 304, 320, 344, 372, 396, 420, 452, 488, 520)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from librosa import filters\n",
    "import torch\n",
    "from einops import rearrange, pack, unpack, reduce, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "# create mel filter bank\n",
    "# with librosa.filters.mel as in section 2 of paper\n",
    "sample_rate = 44100\n",
    "stft_n_fft = 2048\n",
    "num_bands = 60\n",
    "stft_hop_length = 441\n",
    "stft_win_length = 2048\n",
    "stft_normalized = False\n",
    "stereo = True\n",
    "audio_channels = 2 if stereo else 1\n",
    "\n",
    "stft_kwargs = dict(\n",
    "    n_fft=stft_n_fft,\n",
    "    hop_length=stft_hop_length,\n",
    "    win_length=stft_win_length,\n",
    "    normalized=stft_normalized\n",
    ")\n",
    "# 首先这里计算得到的频率数量是 1025，因为 n_fft 是 2048，所以频率数量是 n_fft // 2 + 1\n",
    "freqs = torch.stft(torch.randn(1, 4096), **stft_kwargs, window=torch.ones(stft_n_fft), return_complex=True).shape[1]\n",
    "\n",
    "# 得到的 mel_filter_bank_numpy 的 shape 是 (num_bands, freqs)\n",
    "mel_filter_bank_numpy = filters.mel(sr=sample_rate, n_fft=stft_n_fft, n_mels=num_bands)\n",
    "\n",
    "mel_filter_bank = torch.from_numpy(mel_filter_bank_numpy)\n",
    "\n",
    "# for some reason, it doesn't include the first freq? just force a value for now\n",
    "# 将 mel_filter_bank 的第一行第一列的值设为 1，因为 mel_filter_bank 的第一行第一列的值是 0，这里强制设为 1，确保所有频率都被所有频带覆盖\n",
    "mel_filter_bank[0][0] = 1.\n",
    "\n",
    "# In some systems/envs we get 0.0 instead of ~1.9e-18 in the last position,\n",
    "# so let's force a positive value\n",
    "# 将 mel_filter_bank 的最后一行最后一列的值设为 1，确保所有频率都被所有频带覆盖\n",
    "mel_filter_bank[-1, -1] = 1.\n",
    "\n",
    "# binary as in paper (then estimated masks are averaged for overlapping regions)\n",
    "# 得到的 freqs_per_band 的 shape 是 (num_bands, freqs)，其中True表示该频率在该频带中，False表示不在\n",
    "freqs_per_band = mel_filter_bank > 0\n",
    "print(f\"freqs_per_band: {freqs_per_band.shape}, {freqs_per_band}\")\n",
    "assert freqs_per_band.any(dim=0).all(), 'all frequencies need to be covered by all bands for now'\n",
    "# 将频率索引的序列（0, 1, 2, ..., 1024）复制 num_bands 次\n",
    "repeated_freq_indices = repeat(torch.arange(freqs), 'f -> b f', b=num_bands)\n",
    "print(f\"repeated_freq_indices: {repeated_freq_indices.shape}, {repeated_freq_indices}\")\n",
    "# 然后根据 mel_filter_bank 的值进行筛选，得到每个频带对应的频率索引，输出为True的索引，False的索引被过滤掉\n",
    "# 布尔索引会将所有标记为 True 的频率索引提取到一个一维张量中，\n",
    "freq_indices = repeated_freq_indices[freqs_per_band]\n",
    "print(f\"1:freq_indices: {freq_indices.shape}, {freq_indices}\")\n",
    "\n",
    "if stereo: # 将索引的序列复制一次，然后每个索引乘以2，再加上0和1，最后将所有索引展平\n",
    "    freq_indices = repeat(freq_indices, 'f -> f s', s=2)\n",
    "    print(f\"2:freq_indices: {freq_indices.shape}, {freq_indices}\")\n",
    "    freq_indices = freq_indices * 2 + torch.arange(2)\n",
    "    print(f\"3:freq_indices: {freq_indices.shape}, {freq_indices}\")\n",
    "    freq_indices = rearrange(freq_indices, 'f s -> (f s)')\n",
    "    print(f\"4:freq_indices: {freq_indices.shape}, {freq_indices}\")\n",
    "\n",
    "# 求True的数量，即每个频带中的频率数量\n",
    "num_freqs_per_band = reduce(freqs_per_band, 'b f -> b', 'sum')\n",
    "print(f\"num_freqs_per_band: {num_freqs_per_band.shape}, {num_freqs_per_band}\")\n",
    "# 求每个频率对应的频带数量\n",
    "num_bands_per_freq = reduce(freqs_per_band, 'b f -> f', 'sum')\n",
    "print(f\"num_bands_per_freq: {num_bands_per_freq.shape}, {num_bands_per_freq}\")\n",
    "\n",
    "# band split and mask estimator\n",
    "\n",
    "freqs_per_bands_with_complex = tuple(2 * f * audio_channels for f in num_freqs_per_band.tolist())\n",
    "\n",
    "print(f\"\"\"freqs: {freqs} \n",
    "mel_filter_bank_numpy: {mel_filter_bank_numpy.shape} ,content: {mel_filter_bank_numpy} \n",
    "freqs_per_band: {freqs_per_band.shape} ,content: {freqs_per_band} \n",
    "freq_indices: {freq_indices.shape} ,content: {freq_indices} \n",
    "num_freqs_per_band: {num_freqs_per_band.shape} ,content: {num_freqs_per_band} \n",
    "freqs_per_bands_with_complex: {freqs_per_bands_with_complex}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_audio: torch.Size([40, 44100]), batch_audio_channel_packed_shape: [torch.Size([20, 2])]\n",
      "num_freqs=1025, num_frames=96, num_frames_pad = 101\n",
      "stft_repr: torch.Size([40, 1025, 101])\n",
      "stft_repr: torch.Size([40, 1025, 101, 2])\n",
      "stft_repr: torch.Size([20, 2, 1025, 101, 2])\n",
      "stft_repr: torch.Size([20, 2050, 101, 2])\n",
      "batch_arange: torch.Size([20, 1])\n",
      "x: torch.Size([20, 3958, 101, 2]), tensor([[[[ 1.9414e+01,  0.0000e+00],\n",
      "          [ 1.6111e+01,  0.0000e+00],\n",
      "          [-1.2920e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.7361e+01,  0.0000e+00],\n",
      "          [ 2.1856e+00,  0.0000e+00],\n",
      "          [-2.2472e+01,  0.0000e+00]],\n",
      "\n",
      "         [[ 7.0733e+01,  0.0000e+00],\n",
      "          [ 4.0397e+01,  0.0000e+00],\n",
      "          [-2.1741e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 5.3809e+01,  0.0000e+00],\n",
      "          [ 2.7783e+01,  0.0000e+00],\n",
      "          [ 1.3805e+01,  0.0000e+00]],\n",
      "\n",
      "         [[-5.3832e+00,  0.0000e+00],\n",
      "          [-1.6903e+01,  2.5503e-01],\n",
      "          [ 3.4481e+00, -3.4564e+01],\n",
      "          ...,\n",
      "          [-2.2660e+01,  1.7031e+01],\n",
      "          [-7.8509e+00, -3.5944e+01],\n",
      "          [ 3.4277e+01,  1.4137e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0084e+01,  0.0000e+00],\n",
      "          [ 1.8806e+01,  1.4571e+01],\n",
      "          [ 9.0398e+00,  2.7514e+01],\n",
      "          ...,\n",
      "          [-7.4802e+01,  1.2927e+01],\n",
      "          [-2.4041e+00, -2.4874e+01],\n",
      "          [-1.3101e+01,  3.3824e-02]],\n",
      "\n",
      "         [[ 3.4894e+01,  0.0000e+00],\n",
      "          [-1.7989e+01,  0.0000e+00],\n",
      "          [-1.6275e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [-4.6799e+01,  0.0000e+00],\n",
      "          [ 7.0282e+00,  0.0000e+00],\n",
      "          [ 9.5239e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-8.3935e+00,  0.0000e+00],\n",
      "          [ 4.7001e+00,  0.0000e+00],\n",
      "          [-1.1589e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 6.2245e+01,  0.0000e+00],\n",
      "          [-4.2484e+01,  0.0000e+00],\n",
      "          [ 1.5177e+01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 8.3075e+00,  0.0000e+00],\n",
      "          [-5.2064e+00,  0.0000e+00],\n",
      "          [-2.5440e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.2873e+01,  0.0000e+00],\n",
      "          [-1.7189e+01,  0.0000e+00],\n",
      "          [-1.6093e+01,  0.0000e+00]],\n",
      "\n",
      "         [[-3.0228e+01,  0.0000e+00],\n",
      "          [-8.5703e+00,  0.0000e+00],\n",
      "          [ 2.2232e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 4.6465e+00,  0.0000e+00],\n",
      "          [-2.5243e+01,  0.0000e+00],\n",
      "          [-5.6372e+01,  0.0000e+00]],\n",
      "\n",
      "         [[-2.0014e+01,  2.8610e-06],\n",
      "          [ 6.8626e+00, -1.9419e+01],\n",
      "          [ 1.7727e+01, -4.1058e+00],\n",
      "          ...,\n",
      "          [ 1.2114e+01, -6.5962e+00],\n",
      "          [ 1.1489e+01,  2.6314e+00],\n",
      "          [ 3.2898e+00, -2.9186e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.3453e+01,  0.0000e+00],\n",
      "          [ 4.9815e+00, -4.3365e+01],\n",
      "          [ 2.4881e+01, -5.1315e+00],\n",
      "          ...,\n",
      "          [ 9.7998e+00,  2.0725e+00],\n",
      "          [-2.7012e+01,  9.8358e+00],\n",
      "          [-5.5629e+00,  1.1063e-01]],\n",
      "\n",
      "         [[-5.8436e+00,  0.0000e+00],\n",
      "          [ 4.8158e-01,  0.0000e+00],\n",
      "          [-8.8409e-01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.3447e+01,  0.0000e+00],\n",
      "          [-1.7751e+01,  0.0000e+00],\n",
      "          [ 3.3004e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 5.0572e+01,  0.0000e+00],\n",
      "          [-1.9205e+01,  0.0000e+00],\n",
      "          [-1.1300e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [-3.8564e+01,  0.0000e+00],\n",
      "          [ 2.7787e+01,  0.0000e+00],\n",
      "          [-2.4934e+01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1929e+01,  0.0000e+00],\n",
      "          [ 3.4628e+01,  0.0000e+00],\n",
      "          [ 3.2335e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.8710e+00,  0.0000e+00],\n",
      "          [ 1.6504e+00,  0.0000e+00],\n",
      "          [ 2.4470e-02,  0.0000e+00]],\n",
      "\n",
      "         [[ 9.8393e+00,  0.0000e+00],\n",
      "          [ 3.7716e+00,  0.0000e+00],\n",
      "          [ 1.2957e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.3155e+01,  0.0000e+00],\n",
      "          [ 5.5716e+01,  0.0000e+00],\n",
      "          [ 6.9118e+01,  0.0000e+00]],\n",
      "\n",
      "         [[-4.9898e+00,  0.0000e+00],\n",
      "          [-1.4349e+01,  1.5644e+01],\n",
      "          [-3.7029e+01, -1.2969e+01],\n",
      "          ...,\n",
      "          [-4.8799e+00,  2.6613e+00],\n",
      "          [ 1.9567e+00, -5.5683e-01],\n",
      "          [-3.3387e+00, -2.0414e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9989e+01, -3.8147e-06],\n",
      "          [-2.3571e+01, -1.5929e+01],\n",
      "          [ 2.4994e+00, -3.0712e+01],\n",
      "          ...,\n",
      "          [-6.8084e+00, -3.0388e+01],\n",
      "          [ 2.9994e+01,  2.9456e+00],\n",
      "          [-1.7030e+01, -3.2954e-02]],\n",
      "\n",
      "         [[-7.0817e+00,  0.0000e+00],\n",
      "          [-9.1031e-01,  0.0000e+00],\n",
      "          [-7.7125e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.3805e+01,  0.0000e+00],\n",
      "          [ 6.6492e+00,  0.0000e+00],\n",
      "          [-6.1848e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-7.2064e+00,  0.0000e+00],\n",
      "          [ 1.2989e+01,  0.0000e+00],\n",
      "          [-3.1080e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.0844e+01,  0.0000e+00],\n",
      "          [-3.8709e+01,  0.0000e+00],\n",
      "          [ 4.4802e+01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.2623e+01,  0.0000e+00],\n",
      "          [ 2.8109e+01,  0.0000e+00],\n",
      "          [-9.8313e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.4242e+00,  0.0000e+00],\n",
      "          [ 2.1274e+01,  0.0000e+00],\n",
      "          [ 3.7446e+01,  0.0000e+00]],\n",
      "\n",
      "         [[-7.5566e+00,  0.0000e+00],\n",
      "          [ 1.0950e+00,  0.0000e+00],\n",
      "          [ 2.0001e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.8790e+01,  0.0000e+00],\n",
      "          [ 2.1154e+01,  0.0000e+00],\n",
      "          [ 3.3911e+01,  0.0000e+00]],\n",
      "\n",
      "         [[-9.0798e+00, -7.6294e-06],\n",
      "          [-3.7360e+01, -8.0198e+00],\n",
      "          [ 2.0876e+01, -4.3835e+01],\n",
      "          ...,\n",
      "          [ 2.9749e+00,  4.9532e-01],\n",
      "          [-8.6022e+00,  2.2249e+01],\n",
      "          [-3.1602e+01, -7.9025e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5144e+01, -1.9073e-06],\n",
      "          [ 2.5066e+01, -3.0911e+01],\n",
      "          [ 1.3406e+01,  9.8327e+00],\n",
      "          ...,\n",
      "          [ 4.7017e+01, -3.7067e+00],\n",
      "          [-6.8454e+00,  4.5826e+01],\n",
      "          [-3.7230e+01,  1.6211e-01]],\n",
      "\n",
      "         [[ 6.8640e+01,  0.0000e+00],\n",
      "          [-2.7213e+01,  0.0000e+00],\n",
      "          [-2.0808e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.3440e+00,  0.0000e+00],\n",
      "          [ 2.0546e+01,  0.0000e+00],\n",
      "          [-2.4160e+01,  0.0000e+00]],\n",
      "\n",
      "         [[ 6.3596e+01,  0.0000e+00],\n",
      "          [-3.7920e+01,  0.0000e+00],\n",
      "          [ 5.6337e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [-5.2901e+01,  0.0000e+00],\n",
      "          [ 1.2949e+01,  0.0000e+00],\n",
      "          [ 2.1622e+01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2439e+01,  0.0000e+00],\n",
      "          [ 4.8176e+01,  0.0000e+00],\n",
      "          [ 2.5792e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.0679e+01,  0.0000e+00],\n",
      "          [ 3.7802e+01,  0.0000e+00],\n",
      "          [ 5.3177e+01,  0.0000e+00]],\n",
      "\n",
      "         [[-2.8965e+01,  0.0000e+00],\n",
      "          [-3.0964e+01,  0.0000e+00],\n",
      "          [-2.5455e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [-1.3654e+01,  0.0000e+00],\n",
      "          [-5.3697e+01,  0.0000e+00],\n",
      "          [-8.5701e+01,  0.0000e+00]],\n",
      "\n",
      "         [[-4.0986e+00, -5.7220e-06],\n",
      "          [-3.7359e+01,  1.4278e+01],\n",
      "          [-2.3682e+01, -4.0060e+01],\n",
      "          ...,\n",
      "          [-1.1808e+00,  6.3699e+00],\n",
      "          [-2.7370e+01,  1.6281e+01],\n",
      "          [-2.6066e+01,  3.2015e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6648e+01,  3.8147e-06],\n",
      "          [-6.2884e+00, -1.9094e+01],\n",
      "          [ 2.0631e+01, -7.7280e-02],\n",
      "          ...,\n",
      "          [-1.3530e+00, -1.0193e+01],\n",
      "          [ 9.2718e+00, -1.0419e+01],\n",
      "          [ 1.2697e+01, -7.1745e-02]],\n",
      "\n",
      "         [[ 6.9554e+01,  0.0000e+00],\n",
      "          [-4.1836e+01,  0.0000e+00],\n",
      "          [ 4.9238e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 6.7874e+00,  0.0000e+00],\n",
      "          [-3.9968e+01,  0.0000e+00],\n",
      "          [ 6.5459e+01,  0.0000e+00]],\n",
      "\n",
      "         [[ 6.4223e+00,  0.0000e+00],\n",
      "          [ 7.3618e+00,  0.0000e+00],\n",
      "          [-2.2598e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 5.5323e+00,  0.0000e+00],\n",
      "          [-3.0780e+00,  0.0000e+00],\n",
      "          [-2.0102e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-4.0881e+01,  0.0000e+00],\n",
      "          [-4.0496e+01,  0.0000e+00],\n",
      "          [-5.2254e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 8.4118e+00,  0.0000e+00],\n",
      "          [ 1.0437e+01,  0.0000e+00],\n",
      "          [ 4.0569e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.5298e+01,  0.0000e+00],\n",
      "          [ 1.8435e+01,  0.0000e+00],\n",
      "          [-7.8320e+00,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 8.4736e+00,  0.0000e+00],\n",
      "          [ 3.1492e+01,  0.0000e+00],\n",
      "          [ 5.2428e+01,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.5485e+01,  1.9073e-06],\n",
      "          [ 2.4926e+01, -1.2444e+00],\n",
      "          [ 1.8539e+01, -9.5531e+00],\n",
      "          ...,\n",
      "          [-1.1704e+01,  2.0772e+01],\n",
      "          [-1.4968e+01, -1.7829e+01],\n",
      "          [ 1.6729e+01,  1.0389e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4917e+00, -1.9073e-06],\n",
      "          [-7.2769e+00,  1.3816e+01],\n",
      "          [-2.9578e+01, -2.6103e+01],\n",
      "          ...,\n",
      "          [-2.5183e+00, -3.1763e+01],\n",
      "          [ 2.1606e+01,  2.2093e+00],\n",
      "          [-1.0996e+01, -2.8954e-02]],\n",
      "\n",
      "         [[-4.0389e+01,  0.0000e+00],\n",
      "          [ 3.2389e+01,  0.0000e+00],\n",
      "          [-2.0085e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.8146e+00,  0.0000e+00],\n",
      "          [ 8.6794e+00,  0.0000e+00],\n",
      "          [-2.0054e+01,  0.0000e+00]],\n",
      "\n",
      "         [[-8.0967e+00,  0.0000e+00],\n",
      "          [-6.3486e+00,  0.0000e+00],\n",
      "          [ 3.7099e+01,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.9065e+00,  0.0000e+00],\n",
      "          [-2.6381e+01,  0.0000e+00],\n",
      "          [ 3.1431e+01,  0.0000e+00]]]])\n"
     ]
    }
   ],
   "source": [
    "# 最终实现Mel频带分解，主要是先将音频得到的STFT结果进行频率索引的筛选，然后再进行频带的合并\n",
    "# to stft\n",
    "from einops import rearrange, pack, unpack, reduce, repeat\n",
    "from functools import partial\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "\n",
    "def default(v, d):\n",
    "    return v if exists(v) else d\n",
    "\n",
    "\n",
    "def pack_one(t, pattern):\n",
    "    return pack([t], pattern)\n",
    "\n",
    "\n",
    "def unpack_one(t, ps, pattern):\n",
    "    return unpack(t, ps, pattern)[0]\n",
    "\n",
    "\n",
    "raw_audio = torch.randn(20, 2, 44100) # [batch_size, num_channels, raw_audio_length]\n",
    "batch, channels, raw_audio_length = raw_audio.shape\n",
    "raw_audio, batch_audio_channel_packed_shape = pack_one(raw_audio, '* t') # [batch_size*num_channels, raw_audio_length]\n",
    "print(f\"raw_audio: {raw_audio.shape}, batch_audio_channel_packed_shape: {batch_audio_channel_packed_shape}\")\n",
    "\n",
    "stft_window_fn = partial(torch.hann_window, stft_win_length)\n",
    "device = raw_audio.device\n",
    "\n",
    "stft_kwargs = dict(\n",
    "    n_fft=stft_n_fft,\n",
    "    hop_length=stft_hop_length,\n",
    "    win_length=stft_win_length,\n",
    "    normalized=stft_normalized\n",
    ")\n",
    "# num_freqs = stft_n_fft // 2 + 1 num_frames = 1 + L // hop_length for center=True, or 1 + (L - n_fft) // hop_length for center=False\n",
    "# center = True, pad_mode = 'reflect',这时，会在两边pad n_fft // 2，所以num_frames = 1 + L // hop_length\n",
    "stft_window = stft_window_fn(device=device)\n",
    "stft_repr = torch.stft(raw_audio, **stft_kwargs, window=stft_window, return_complex=True) # [batch_size*num_channels, num_freqs, num_frames]\n",
    "print(f\"stft_repr: {stft_repr.shape}\")\n",
    "stft_repr = torch.view_as_real(stft_repr)# [batch_size*num_channels, num_freqs, num_frames, 2]\n",
    "print(f\"stft_repr: {stft_repr.shape}\")\n",
    "\n",
    "stft_repr = unpack_one(stft_repr, batch_audio_channel_packed_shape, '* f t c') # [batch_size, num_channels, num_freqs, num_frames, 2]\n",
    "print(f\"stft_repr: {stft_repr.shape}\")\n",
    "stft_repr = rearrange(stft_repr,\n",
    "                        'b s f t c -> b (f s) t c')  # merge stereo / mono into the frequency, with frequency leading dimension, for band splitting\n",
    "print(f\"stft_repr: {stft_repr.shape}\") # [batch_size, num_freqs*num_channels, num_frames, 2]\n",
    "\n",
    "# index out all frequencies for all frequency ranges across bands ascending in one go\n",
    "\n",
    "batch_arange = torch.arange(batch, device=device)[..., None] # [batch_size, 1]\n",
    "print(f\"batch_arange: {batch_arange.shape}\")\n",
    "# account for stereo\n",
    "\n",
    "x = stft_repr[batch_arange, freq_indices] # 根据freq_indices 的索引，将每个音频对应的STFT结果进行频率索引的筛选，按照mel freq的索引进行扩充拉平\n",
    "# [batch_size, 1+sum(mel_freqs), num_frames, 2]\n",
    "print(f\"x: {x.shape}, {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Compute Capability equal or above 8.0, using flash attention if input tensor is on cuda\n",
      "28 384\n",
      "24 384\n",
      "24 384\n",
      "24 384\n",
      "24 384\n",
      "24 384\n",
      "24 384\n",
      "24 384\n",
      "24 384\n",
      "24 384\n",
      "24 384\n",
      "24 384\n",
      "24 384\n",
      "24 384\n",
      "24 384\n",
      "28 384\n",
      "28 384\n",
      "28 384\n",
      "36 384\n",
      "36 384\n",
      "36 384\n",
      "40 384\n",
      "40 384\n",
      "44 384\n",
      "52 384\n",
      "52 384\n",
      "52 384\n",
      "60 384\n",
      "64 384\n",
      "68 384\n",
      "76 384\n",
      "80 384\n",
      "80 384\n",
      "88 384\n",
      "96 384\n",
      "104 384\n",
      "112 384\n",
      "116 384\n",
      "124 384\n",
      "132 384\n",
      "144 384\n",
      "156 384\n",
      "164 384\n",
      "176 384\n",
      "188 384\n",
      "200 384\n",
      "216 384\n",
      "228 384\n",
      "244 384\n",
      "264 384\n",
      "284 384\n",
      "304 384\n",
      "320 384\n",
      "344 384\n",
      "372 384\n",
      "396 384\n",
      "420 384\n",
      "452 384\n",
      "488 384\n",
      "520 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 60, 384])\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=56, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=48, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=56, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=56, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=56, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=72, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=72, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=72, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=80, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=80, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=88, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=104, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=104, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=104, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=120, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=128, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=136, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=152, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=160, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=160, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=176, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=192, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=208, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=224, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=232, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=248, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=264, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=288, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=312, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=328, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=352, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=376, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=400, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=432, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=456, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=488, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=528, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=568, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=608, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=640, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=688, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=744, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=792, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=840, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=904, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=976, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n",
      "torch.Size([2, 10, 384]) Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=1536, out_features=1040, bias=True)\n",
      "  )\n",
      "  (1): GLU(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from utils import demix, get_model_from_config\n",
    "import json\n",
    "\n",
    "model_type = 'mel_band_roformer'\n",
    "config_path = 'configs/KimberleyJensen/config_musdb18_vocals_mel_band_roformer_kj_with_augue.yaml'\n",
    "model, config = get_model_from_config(model_type, config_path)\n",
    "\n",
    "import torch\n",
    "x = torch.randn(2, 2, 4096, dtype=torch.float32)\n",
    "y = torch.randn(2, 2, 4096, dtype=torch.float32)\n",
    "loss = model(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查 Mel band llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager\n",
      "Total number of parameters: 232856772, 232.86M\n",
      "Total number of parameters (in MB): 931.43 MB\n",
      "[\n",
      "    \"layers.0.0.self_attn.q_proj.weight\",\n",
      "    \"layers.0.0.self_attn.k_proj.weight\",\n",
      "    \"layers.0.0.self_attn.v_proj.weight\",\n",
      "    \"layers.0.0.self_attn.o_proj.weight\",\n",
      "    \"layers.0.0.mlp.gate_proj.weight\",\n",
      "    \"layers.0.0.mlp.up_proj.weight\",\n",
      "    \"layers.0.0.mlp.down_proj.weight\",\n",
      "    \"layers.0.0.input_layernorm.weight\",\n",
      "    \"layers.0.0.post_attention_layernorm.weight\",\n",
      "    \"layers.0.1.self_attn.q_proj.weight\",\n",
      "    \"layers.0.1.self_attn.k_proj.weight\",\n",
      "    \"layers.0.1.self_attn.v_proj.weight\",\n",
      "    \"layers.0.1.self_attn.o_proj.weight\",\n",
      "    \"layers.0.1.mlp.gate_proj.weight\",\n",
      "    \"layers.0.1.mlp.up_proj.weight\",\n",
      "    \"layers.0.1.mlp.down_proj.weight\",\n",
      "    \"layers.0.1.input_layernorm.weight\",\n",
      "    \"layers.0.1.post_attention_layernorm.weight\",\n",
      "    \"layers.1.0.self_attn.q_proj.weight\",\n",
      "    \"layers.1.0.self_attn.k_proj.weight\",\n",
      "    \"layers.1.0.self_attn.v_proj.weight\",\n",
      "    \"layers.1.0.self_attn.o_proj.weight\",\n",
      "    \"layers.1.0.mlp.gate_proj.weight\",\n",
      "    \"layers.1.0.mlp.up_proj.weight\",\n",
      "    \"layers.1.0.mlp.down_proj.weight\",\n",
      "    \"layers.1.0.input_layernorm.weight\",\n",
      "    \"layers.1.0.post_attention_layernorm.weight\",\n",
      "    \"layers.1.1.self_attn.q_proj.weight\",\n",
      "    \"layers.1.1.self_attn.k_proj.weight\",\n",
      "    \"layers.1.1.self_attn.v_proj.weight\",\n",
      "    \"layers.1.1.self_attn.o_proj.weight\",\n",
      "    \"layers.1.1.mlp.gate_proj.weight\",\n",
      "    \"layers.1.1.mlp.up_proj.weight\",\n",
      "    \"layers.1.1.mlp.down_proj.weight\",\n",
      "    \"layers.1.1.input_layernorm.weight\",\n",
      "    \"layers.1.1.post_attention_layernorm.weight\",\n",
      "    \"layers.2.0.self_attn.q_proj.weight\",\n",
      "    \"layers.2.0.self_attn.k_proj.weight\",\n",
      "    \"layers.2.0.self_attn.v_proj.weight\",\n",
      "    \"layers.2.0.self_attn.o_proj.weight\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from utils import demix, get_model_from_config\n",
    "import json\n",
    "\n",
    "model_type = 'mel_band_llama'\n",
    "config_path = 'configs/KimberleyJensen/config_musdb18_vocals_mel_band_roformer_kj_with_augue.yaml'\n",
    "model, config = get_model_from_config(model_type, config_path)\n",
    "\n",
    "# 计算模型的总参数量\n",
    "total_params = sum(param.numel() for param in model.state_dict().values())\n",
    "\n",
    "# 打印总参数量，单位是个数\n",
    "print(f\"Total number of parameters: {total_params}, {total_params/1e6:.2f}M\")\n",
    "\n",
    "# 如果需要显示以MB为单位的参数量\n",
    "params_in_mb = total_params * 4 / 1e6  # 假设每个参数占 4 字节（float32）\n",
    "print(f\"Total number of parameters (in MB): {params_in_mb:.2f} MB\")\n",
    "print(json.dumps(list(model.state_dict().keys())[:40], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randn(2, 2, 4096, dtype=torch.float32)\n",
    "y = torch.randn(2, 2, 4096, dtype=torch.float32)\n",
    "loss = model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, transformer_block in enumerate(model.layers):\n",
    "    \n",
    "    if len(transformer_block) == 3:\n",
    "        linear_transformer, time_transformer, freq_transformer = transformer_block\n",
    "\n",
    "        x, ft_ps = pack([x], 'b * d')\n",
    "\n",
    "        x = linear_transformer(x)\n",
    "        x, = unpack(x, ft_ps, 'b * d')\n",
    "    else:\n",
    "        time_transformer, freq_transformer = transformer_block\n",
    "        print(f\"i: {i}, time_transformer: \\n {time_transformer}, freq_transformer:  \\n {freq_transformer}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from transformers.utils import is_flash_attn_2_available\n",
    "print(is_flash_attn_2_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查两个的rope embedding 是否能够相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([352800, 48]) torch.Size([352800, 48])\n",
      "tensor([[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "        [ 0.5403,  0.7768,  0.8942,  ...,  1.0000,  1.0000,  1.0000],\n",
      "        [-0.4161,  0.2067,  0.5992,  ...,  1.0000,  1.0000,  1.0000],\n",
      "        ...,\n",
      "        [-0.7561,  0.6777,  0.0868,  ...,  0.0377,  0.8199,  0.0527],\n",
      "        [-0.9592,  0.0727, -0.3726,  ...,  0.0380,  0.8198,  0.0526],\n",
      "        [-0.2804, -0.5767, -0.7517,  ...,  0.0383,  0.8196,  0.0524]]) tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.0000e+00, 1.0000e+00, 6.8129e-01,  ..., 2.1544e-04, 1.4678e-04,\n",
      "         1.4678e-04],\n",
      "        [2.0000e+00, 2.0000e+00, 1.3626e+00,  ..., 4.3089e-04, 2.9356e-04,\n",
      "         2.9356e-04],\n",
      "        ...,\n",
      "        [3.5280e+05, 3.5280e+05, 2.4036e+05,  ..., 7.6008e+01, 5.1784e+01,\n",
      "         5.1784e+01],\n",
      "        [3.5280e+05, 3.5280e+05, 2.4036e+05,  ..., 7.6008e+01, 5.1784e+01,\n",
      "         5.1784e+01],\n",
      "        [3.5280e+05, 3.5280e+05, 2.4036e+05,  ..., 7.6008e+01, 5.1784e+01,\n",
      "         5.1784e+01]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "seq_length = 352800\n",
    "t = torch.ones(1, 1, seq_length, 128, dtype=torch.float32)\n",
    "\n",
    "from rotary_embedding_torch import RotaryEmbedding\n",
    "mel_band_roformer_rope_embedding = RotaryEmbedding(48)\n",
    "\n",
    "device, dtype, seq_len = t.device, t.dtype, t.shape[-2]\n",
    "\n",
    "seq = mel_band_roformer_rope_embedding.get_seq_pos(seq_len, device = device, dtype = dtype, offset = 0)\n",
    "\n",
    "freqs = mel_band_roformer_rope_embedding.forward(seq, seq_len = seq_len, offset = 0)\n",
    "        \n",
    "from transformers import LlamaConfig\n",
    "from transformers.models.llama.modeling_llama import LlamaRotaryEmbedding\n",
    "config = LlamaConfig(\n",
    "    hidden_size=384,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=384 * 4,  # Llama 默认前馈网络扩展为 4 倍\n",
    "    rms_norm_eps=1e-6,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_dropout_prob=0.1,\n",
    "    rope_theta=10000.0  # 默认值，可调整\n",
    ")\n",
    "mel_band_llama_rotary_emb = LlamaRotaryEmbedding(config=config)\n",
    "\n",
    "def get_pos_ids(seq_length, device):\n",
    "    return torch.arange(seq_length, device=device).unsqueeze(0)\n",
    "\n",
    "pos_ids = get_pos_ids(seq_length, 'cpu')\n",
    "mel_band_llama_embedding = mel_band_llama_rotary_emb(t, pos_ids)[0].squeeze(0)\n",
    "\n",
    "print(mel_band_llama_embedding.shape, freqs.shape)\n",
    "assert mel_band_llama_embedding.shape == freqs.shape\n",
    "print(mel_band_llama_embedding, freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看split 和 unbind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([2, 4096, 400, 128])\n",
      "x: torch.Size([2, 4096, 16, 128]), torch.Size([2, 4096, 128, 128]), torch.Size([2, 4096, 256, 128])\n",
      "x: torch.Size([2, 4096, 400, 128])\n",
      "torch.Size([2, 4096, 128])\n",
      "torch.Size([2, 4096, 128])\n",
      "torch.Size([2, 4096, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "dim_inputs = (16,128,256)\n",
    "mlp_list = nn.ModuleList()\n",
    "for dim_in in dim_inputs:\n",
    "    mlp_list.append(nn.Linear(dim_in, dim_in))\n",
    "f = 16+128+256\n",
    "f = f // 2\n",
    "b = 2\n",
    "t = 4096\n",
    "c = 2\n",
    "x = torch.randn(b, f, t, c, 128, dtype=torch.float32)\n",
    "# [b f t c]\n",
    "x = rearrange(x, 'b f t c d -> b t (f c) d')\n",
    "print(f\"x: {x.shape}\")\n",
    "x = x.split(dim_inputs, dim=-2)\n",
    "print(f\"x: {x[0].shape}, {x[1].shape}, {x[2].shape}\")\n",
    "x = torch.cat(x, dim=-2)\n",
    "print(f\"x: {x.shape}\")\n",
    "x = x.unbind(dim=-2)\n",
    "for band_feature, mlp in zip(x, mlp_list):\n",
    "    print(band_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看重复indices的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scatter_indices: torch.Size([2, 1, 6, 2]), tensor([[[[1, 1],\n",
      "          [2, 2],\n",
      "          [3, 3],\n",
      "          [2, 2],\n",
      "          [3, 3],\n",
      "          [4, 4]]],\n",
      "\n",
      "\n",
      "        [[[1, 1],\n",
      "          [2, 2],\n",
      "          [3, 3],\n",
      "          [2, 2],\n",
      "          [3, 3],\n",
      "          [4, 4]]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as self tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscatter_indices: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscatter_indices\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscatter_indices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m stft_repr_expanded_stems \u001b[38;5;241m=\u001b[39m repeat(stft_repr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb 1 ... -> b n ...\u001b[39m\u001b[38;5;124m'\u001b[39m, n\u001b[38;5;241m=\u001b[39mnum_stems)\n\u001b[0;32m---> 14\u001b[0m masks_summed \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstft_repr_expanded_stems\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscatter_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as self tensor"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import repeat\n",
    "\n",
    "# need to average the estimated mask for the overlapped frequencies\n",
    "masks = [[[0.1, 0.2, 0.3, 0.4, 0.5, 0.6]]]\n",
    "masks = torch.tensor(masks, dtype=torch.float32)\n",
    "freq_indices = torch.tensor([1,2,3,2,3,4], dtype=torch.long)\n",
    "batch = 2\n",
    "num_stems = 1\n",
    "stft_repr = torch.randn(batch, num_stems, 2, dtype=torch.float32)\n",
    "scatter_indices = repeat(freq_indices, 'f -> b n f t', b=batch, n=num_stems, t=stft_repr.shape[-1])\n",
    "print(f\"scatter_indices: {scatter_indices.shape}, {scatter_indices}\")\n",
    "stft_repr_expanded_stems = repeat(stft_repr, 'b 1 ... -> b n ...', n=num_stems)\n",
    "masks_summed = torch.zeros_like(stft_repr_expanded_stems).scatter_add_(2, scatter_indices, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
